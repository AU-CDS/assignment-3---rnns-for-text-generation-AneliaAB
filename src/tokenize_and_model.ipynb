{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing(filepath):\n",
    "    corpus = create_corpus(filepath)\n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    inp_sequences = get_sequence_of_tokens(tokenizer, corpus)\n",
    "\n",
    "    return tokenizer, inp_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padded_sequences(filepath):\n",
    "    tokenizer, input_sequences = tokenizing(filepath)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    corpus = create_corpus(filepath)\n",
    "\n",
    "    # get the length of the longest sequence\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    # make every sequence the length of the longest on\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, \n",
    "                                            maxlen=max_sequence_len, \n",
    "                                            padding='pre'))\n",
    "\n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, \n",
    "                            num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors, label, max_sequence_len = padded_sequences(\"../../news_data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
